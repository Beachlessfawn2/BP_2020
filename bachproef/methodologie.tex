%%=============================================================================
%% Methodologie
%%=============================================================================

\chapter{\IfLanguageName{dutch}{Methodologie}{Methodology}}
\label{ch:methodologie}

%% TODO: Hoe ben je te werk gegaan? Verdeel je onderzoek in grote fasen, en
%% licht in elke fase toe welke stappen je gevolgd hebt. Verantwoord waarom je
%% op deze manier te werk gegaan bent. Je moet kunnen aantonen dat je de best
%% mogelijke manier toegepast hebt om een antwoord te vinden op de
%% onderzoeksvraag.
Aucxis werkt momenteel hoofdzakelijk met ‘.NET’ projecten. Als IDE wordt er Visual Studio gebruikt. Als versiebeheer gebruiken ze hiervoor TFVC. Dit was een voor een lange tijd een goede oplossing. De testen die werden uitgevoerd waren vooral functionele testen. Dit is niet ideaal. Er wordt op moment van implementatie bij klanten veel fouten en bugs vastgesteld waardoor er enerzijds veel frustratie ontstaat bij de mensen die het uitrollen bij een klant. Anderzijds wordt er veel tijd en geld verloren met het over en weer verplaatsen tussen klant en bedrijf. Aucxis heeft recent een keuze gemaakt om meer te investeren in kwaliteit. Aangezien Aucxis al een verwent gebruiker van Microsoft is, was de keuze voor Azure DeVops niet moeilijk. Ook heeft dit minder impact op hun huidige werkwijze.

Zoals eerder aangehaald worden er vooral functionele testen uitgevoerd. Met de stap naar kwalitatievere oplossingen is er ook nood voor meerdere soorten testen. Het ideale zou zijn dat er naast functionele testen ook in een gecontroleerde omgeving, die een situatie bij de klant in kwestie nabootst, getest kan worden. Daarna zou het programma bij een test omgeving van de klant uitgerold worden om daar te worden getest. In een finale stap, zou het programma dan in productie worden uitgerold. Dit alles zou zo geautomatiseerd mogelijk moeten verlopen.

Azure DeVops lijkt hier het meest geschikt voor om deze functionaliteit te verkrijgen. Daarom de vraag om toch het aanbod van Azure met de andere Cloud platform aanbieders te vergelijken en het beste alternatief te selecteren. Om dit te bereiken is er in dit onderzoek begonnen met kort de verschillende Cloud platformen hun aanbod naast elkaar te leggen.

\section{Vergelijking}
\subsection{Azure DeVops}
Microsoft Azure is gelanceerd in 2010 en bevat een hele serie producten. Azure biedt vooral producten aan in de categorieën Software as a Service (SaaS), Infrastructure as a Service (Iaas) \& Platform as a Service (PaaS). Azure heeft een aantal zeer goede producten voor virtualisatie. Zo Biedt Azure een enorm aanbod aan verschillende soorten machines aan voor verschillende doeleindes. Ook hun virtuele netwerkmogelijkheden zijn enorm. Dit alles is mooi geordend en zeer gemakkelijk in gebruik. De Azure datacenters zijn over heel de wereld verspreid. Deze zijn altijd het nieuwste van het nieuwste en zijn zeer goed verbonden onderling en met de buitenwereld. Omdat Azure van Microsoft is, is Azure ook perfect te integreren met bestaan gebruikers accounts in domeinen. Dit geeft de gebruiker volledige controle over wie wat kan gebruiken en zien. Azure biedt ook een aantal services aan. Daarvan is Cloud gebaseerde Active Directory er een van. Ook bieden ze een volledig aanbod aan services aan om een CI/CD pijpleiding te realiseren.

Azure DeVops was vroeger bekend als Visual Studio Team System (VSTS) of Team Foundation Server (TFS). Het is een versie beheer, rapportering, vereisten beheer, project beheer, automatisch compileer, test en uitrol beheer tool gemaakt door Microsoft. De tool maakt gebruik van Team Foundation Version Control (TFVC) of Git. De tool is gemaakt om de volledige levenscyclus van een programma te controleren en beheren. Ook biedt de tool de mogelijkheid aan programmeerteams om in een DeVops sfeer samen te werken. Het mooie aan deze tool is dat het bijna in iedere Integrated Development Environment (IDE) te integreren is.

Het is mogelijk om deze tool zowel lokaal als in de Cloud te implementeren. Microsoft heeft deze tool toegevoegd aan hun Azure aanbod onder Azure DeVops. Microsoft heeft de verschillende componenten van deze tool opgesplitst op het platform. Dit maakt het mogelijk dat de gebruiker niet alle componenten tegelijk hoeft te gebruiken of te implementeren. De gebruiker kan zo naar hun voorkeur functie kiezen.

Azure DeVops kan gebruikmaken van twee soorten versie controle in een project. Het kan gebruikmaken van de door Microsoft speciaal ontwikkelde versie beheer framework TFVC voor Azure DeVops of het wereld befaamde Git. 

TFVC ondersteund twee manieren van werken, met een centraal systeem of lokaal met check-out/ check-in op de computer van de programmeur. Bij het gebruik van een centraal systeem worden files die door een andere programmeur gebruikt worden als ‘alleen lezen’ bestempeld. Dit kan leiden tot problemen als andere programmeurs deze files nodig hebben voor bepaalde zaken. Dit heeft Microsoft proberen oplossen door het mogelijk te maken om volledig lokaal te werken. De programmeur kan dan alle files aanpassen waar nodig. Eventuele problemen met verschillende files moeten dan worden opgelost bij check-in. Dit maakt het mogelijk dat er veel minder conflicten ontstaan. Een ander voordeel is dat de gebruiker de mogelijkheid heeft om met TFVC, regels te configureren die bij check-in worden uitgevoerd.

Git is een veel gebruikt versie beheersysteem. Bijna alle IDE’s bieden ondersteuning aan voor dit systeem. Het werkt gelijkaardig zoals TFVC. Alleen kan de gebruiker met Git geen regels configureren die worden uitgevoerd bij check-in. Git is wel volledig compatibel met Azure DeVops. Zo kan er rechtstreeks met Git op Azure DeVops gepubliceerd worden. Dit alles zorgt ervoor dat gebruikers door gebruik van Git, met bijna iedere IDE of programmeertaal, Azure Devops kan gebruiken. 

Een ander voordeel van Azure DeVops is de uitgebreide rapportering ingebouwd in de tool. Deze maakt het mogelijk om uitgebreide verslagen te genereren van de uitgevoerde testen, een uitgevoerde check-in, compilatie problemen, enz. Ook staat het de gebruiker toe om gepaste meldingen te versturen of automatisatie te configureren om bepaalde problemen op te lossen. Daarnaast heeft Azure Devops ook een ingebouwde tool om planningen voor projecten bij te houden.

Azure Boards is letterlijk een volledige implementatie rechtstreeks in Azure DeVops van een scrum bord. Zo kan de gebruiker bij het opleveren van een uitgevoerde taak automatisch de compilatie pijpleiding laten starten. Ook is het volledig geïntegreerd met GitHub waardoor de gebruiker geen extra kosten moet maken om een Azure Repository aan te maken. Ook bestaat de mogelijkheid om Azure boards naadloos te laten samenwerken met de populairste chat applicaties voor ontwikkelaars, zoals Slack.

In Azure DeVops als een gebruiker een CI pijpleiding wil configureren, kan de gebruiker dat simpel via de web interface doen of met de Azure powershell add-on. Azure DeVops gebruikt zoals eerder vermeld, twee soorten versie beheer tools. Om met Git een pijpleiding te bouwen selecteert de gebruikt simpel weg als bron een git repository. Daarna kan de gebruiker kiezen uit een hele serie voor gemaakte motoren voor het compileren van de code. Ook door gebruik te maken van een marktplaats kunnen er zelfs volledig aangepaste motoren gebruikt worden. Hierna wordt de gebruiker gevraagd om een azure-pipelines.yml aan te maken in de broncode waarin dan de configuratie geschreven wordt voor de uit te voeren compilatie. De gebruiker kan dan nog stappen toevoegen voor testen uit te voeren. Azure DeVops heeft de mogelijkheid om op verschillende manieren de software uit te rollen. Gaande van in de Cloud naar specifieke lokale omgevingen enz.

Azure Devops prijzen worden beschreven in figuur~\ref{fig:A_DO_Money}.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{/Users/kenzie/Documents/HoGent/Bachelorproef/Images/Azure_DO_money.png}
    \caption{Figuur van \href{https://azure.microsoft.com/nl-nl/pricing/details/devops/azure-devops-services/}{Azure DeVops website}. Figuur toont de prijzen voor Azure DeVops op een beknopte manier.}
    \label{fig:A_DO_Money}
\end{figure}

Azure DeVops is in dit onderzoek het vertrekt punt voor de vergelijkingen. Dit omdat het perfect met de huidige werkwijze van Aucxis integreert en omdat zij reeds Microsoft partner zijn. In alle vergelijkingen zal gekeken worden of Git gebruikt kan worden omdat dit het een stuk gemakkelijker maakt voor de vergelijkingen. Aucxis ontwikkelt veel applicaties in .NET Core en daarom moet er ook gekeken worden of de alternatieve hiervoor compatible zijn. Azure DeVops is dus het zeer capabele vertrek punt voor de vergelijkingen met de andere Cloud platform aanbieders.
\subsection{Google Cloud}
Google Cloud Platform (GCP) is gelanceerd in April 2008. Het draaide des tijds in dezelfde datacenters als ‘google search’, ‘youtube’ en ‘gmail’. Het was slechts in 2011 dat GCP beschikbaar was voor het brede publiek. GCP is een onderdeel van de Google Cloud. Google Cloud biedt een enorme serie van producten aan waarvan GCP maar een klein onderdeel is. GCP specifiek, biedt ‘infrastructure as a service’ (IaaS), ‘platform as a service’ (PaaS) en ‘serverless computing’ aan. 

Omdat het doel van dit onderzoek specifiek de support voor CI/CD pijpleidingen vergelijken is, bekijken we een specifiek onderdeel van GCP. De ‘Cloud Developper Tools’. Onder deze categorie vallen er een aantal zeer interessante tools. Hier vindt men onder andere ‘Cloud Build’, ‘Cloud-SDK’, ‘Tools voor Powershell’, ‘Tools voor Visual Studio’, enz.

Cloud Build is Google zijn antwoord op een volledige geautomatiseerde CI/CD pijpleiding. Het is dan ook volledig mede met de moderne vereisten. Met Google Cloud Build (GCB) is een organisatie instaat om snel en gemakkelijk een volledige pijpleiding te configureren. Het gelijkt dan ook op Azure DeVops.

GCB werkt hoofdzakelijk met Git en GitHub om een pijpleiding te bouwen. Google heeft ook zijn eigen ‘Cloud repository service’ die naadloos integreert met GCB, maar deze is helaas betalend. Daarom is het gebruik van Git met GitHub een beter en goedkoper alternatief. Aangezien deze ook perfect integreren met GCB en omdat Git wijdverspreid en simpel in gebruik is. Een organisatie kan dan configureren op GCB dat bij het moment van een code update op GitHub, automatisch een compileer pijpleiding wordt gestart. Om GCB te laten weten wat er specifiek moet uitgevoerd worden, moet er op de GitHub repository een YML-file voorzien worden waarin regels gedefinieerd moeten worden. Dit maakt het gemakkelijk om snel aanpassingen te maken.

De pijpleiding op GCB werkt op basis van Docker images. Deze worden in de cloudbuild.yml gedefinieerd. Ook wordt er per Docker container gedefinieerd wat er moet uitgevoerd worden in de vorm van commando’s, script, enz. Dit maakt het mogelijk dat iedere stap in het CI gedeelte van de pijpleiding volledig aangepast kan worden naar de noden van de organisatie. Zo kan de organisatie beslissen om voor gemaakte containers te gebruiken van de ‘DockerHub’ pagina. Ook kan de organisatie zelf container maken met aangepaste scripts om bijvoorbeeld in lokale omgevingen testen uit te voeren. GCB kan dus in een hybride opstelling geïmplementeerd worden. Wat ook de bedoeling zou zijn aangezien dit een use case van Aucxis is. Daarnaast biedt GCB ook de mogelijkheid om de gecompileerde code rechtstreeks vanuit Google Cloud beschikbaar te maken voor verdere verdeling.

Met behulp van deze containers kunnen dan functionele testen uitgevoerd worden op de gecompileerde code. Het programma kan dan op basis van de uitkomst van deze uitgevoerde taak, naar de volgende stap zijn wachtrij worden geplaatst. Hier kan dan de volgende taak starten. GCB genereert rapporten en statistieken van de uitgevoerde taken zodanig dat de gebruiker van het platform inzicht kan krijgen in de uitgevoerde taken.

De compilatie en uitvoer-tijden van GCB zijn zeer goed aangezien het platform automatisch schaalt naarmate er meer rekwesten tegelijk verstuurd worden. Dit maakt mogelijk dat verschillende programmeurs tegelijk aan hetzelfde project werken of aan meerdere projecten tegelijk. Ook biedt GCB de mogelijkheid om redundantie te voorzien. GCB maakt het mogelijk om naar andere Cloudplatformen uit te rollen of zelfs om de werklast te verdelen over verschillende Cloud platformen. Dit is mogelijk door gebruik te maken van Tekton. Tekton is een open-source framework voor Kubernetes. Dit maakt het mogelijk dat een organisatie over verschillende Cloud platformen heen kan werken. Kubernetes is een clustering hypervisor voor Docker containers. Tekton zou een goede oplossing kunnen zijn voor CI/CD pijpleidingen in de Cloud maar valt hier buiten beschouwen vermits het doel de verschillende aanbiedingen van de Cloud platformen vergelijken is.

De prijzen in Google Cloud worden berekend zoals bij ieder moderne Cloud aanbieder. De gebruiker betaald wat hij verbruikt. De volgende figuur~\ref{fig:GCP_BC_money} moet dienen om een beeld te vormen over wat men kan verwachten te betalen voor het gebruik van GCB. Dit zonder netwerk kosten voor het transfereren van gegevens. Er wordt ook niks in rekening gebracht voor zaken die in een wachtrij staan of pijpleidingen die niet gebruikt worden. De Google Cloud Developper Tools hebben een voordeel dat een groot deel van de tools voor ondersteuning met het platform gratis zijn. Er zijn ook weinig tools van derden nodig om de gewilde functionaliteit te bereiken.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{/Users/kenzie/Documents/HoGent/Bachelorproef/Images/gcp_bc_money.png}
    \caption{Figuur van \href{https://cloud.google.com/cloud-build/pricing}{Google Cloud website}. Figuur toont de prijzen voor Google Cloud Platform op een beknopte manier.}
    \label{fig:GCP_BC_money}
\end{figure}

Met andere woorden is GCB dus een volwaardig alternatief voor Azure DeVops. Er is ondersteuning voor verschillende tools, biedt uitgebreide functionaliteiten aan en bovendien adverteert Google dat het gemakkelijk samenwerkt met andere Cloudplatformen. Het zei door het gebruik van Tekton. Daarnaast is het ook relatief simpel in gebruik door dat GCB gebruikmaakt van Docker containers voor te compileren.

\subsection{Amazon Web Services}
Amazon web services (AWS) is gelanceerd in 2006. Gedurende lange tijd heeft Amazon stukken van hun datacenter verhuurd aan het brede publiek. Tegenwoordig kan een gebruiker op AWS een Cloud computer samenstellen juist zoals een gewone server samengesteld zou worden. Het is maar in recente tijden dat Amazon zich meer beginnen focussen is op services die de gebruiker kan gebruiken. Zo bevat AWS nu meer dan 212 services en producten. Bijvoorbeeld: virtuele computerkracht, netwerking, opslag in de Cloud, databases, statistieken, programma services, uitrol op de Cloud, beheer van bepaalde zaken, programmeertools en tools voor Internet Of Things (IoT). De populairste tegenwoordig zijn Amazon Elastic Compute Cloud (EC2) en Amazon Simple Storage Service (Amazon S3). Deze laatste zijn in feite Cloud computerkracht en opslag voor van alles die volledig schaalbaar zijn en die geen kosten hebben om aan te maken.

Ondanks dit groot aanbod resteert er toch nog altijd de vraag hoe het zit met de huidige prestatie van Amazon datacenters over de hele wereld. Zeker na het lezen van deze paper \autocite{Jackson2010}. Voor dit onderzoek is er ijverig gezocht naar recentere prestatie onderzoeken maar zonder resultaat. Er kan alleen maar afgegaan worden van Amazon zijn website.

Al deze producten en services maken het niet gemakkelijk voor een gebruiker om snel te weten welke producten juist voor hem geschikt zijn. Ook in dit onderzoek is er vastgesteld dat het lastig was om een duidelijk beeld te krijgen wat er allemaal aangeboden wordt. Dat terzijde, heeft Amazon toch een specifiek aanbod om CI/CD pijpleidingen te implementeren op hun Cloud platform. Zo heeft Amazon, AWS CodePipeline. Dit is een service waarbij de gebruiker of organisatie via het web portaal gemakkelijk een CI/CD pijpleiding kan definiëren. Deze is volledig aanpasbaar naar de noden van de gebruiker. AWS CodePipeline gebruikt AWS CodeBuild voor de compilatie en het testen van projecten in CI/CD en AWS CodeDeploy voor de automatische uitrol van projecten.

Zoals alle grote Cloud platformen ondersteund AWS CodePipeline ook het gebruik van Git en GitHub. De gebruiker hoeft dus geen speciale zaken te doen. Amazon heeft ook zijn eigen Cloud repositories voor code in op te slaan. Deze zijn ook gebaseerd op Git. Het zijn eigenlijk privé Git repositories die door Amazon worden aangeboden. Het gebruik verschilt niet tussen GitHub en Amazon zijn privé Git servers. De gebruiker kan gemakkelijk via het web portaal de gewenste Git-projecten toevoegen aan AWS CodePipeline.

AWS CodeBuild is een CI service die code compileert, testen uitvoert en als resultaat uitrolbare software oplevert. AWS CodeBuild is speciaal omdat er geen nood is om zelf de server infrastructuur te configureren voor de compilatie van code. AWS CodeBuild doet dit allemaal voor de gebruiker en schaalt mede naarmate de belasting of het project groter wordt. AWS CodeBuild maakt gebruik van voorverpakte compileer omgevingen maar de gebruiker heeft wel de mogelijkheid om zelf zijn compilatie omgevingen te configureren. Dit maakt mogelijk dat de pijpleiding volledig aan te passen is naar de noden van de gebruiker. Zodat Amazon weet wat voor compilatie omgeving er moet gebouwd worden, moet de gebruiker aan de project folder een BuildSpec.yml toevoegen waarin staat welke compileer motor er gebruikt moet worden met welke files. Dit kan ook gedefinieerd worden in het web portaal zodanig dat de gebruiker niet de hele tijd de broncode moet updaten bij wijzigingen aan de configuratie. Ook heeft AWS CodeBuild een voordeel. Na dat de compilatie en testen geslaagd zijn kan er direct een zip gemaakt worden die dan downloadbaar is van Amazon zijn Cloud opslag. Dit is een voordeel aangezien het bij Google niet duidelijk was of dit mogelijk is op die manier. Google wilt alles verpakken in Docker containers die dan wel beschikbaar zijn. AWS CodeBuild zijn prijzen worden op dezelfde manier berekend als Google Cloud Build. Er wordt betaald per minuut dat er computerkracht gebruikt wordt. Zie de figuur~\ref{fig:AWS_CB_money} en figuur~\ref{fig:AWS_CB_money2}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{/Users/kenzie/Documents/HoGent/Bachelorproef/Images/AWS_CB_money.png}
    \caption{Figuur van \href{}{AWS website}. Figuur toont de prijzen van AWS per rekenkracht, OS en verstreken minuut.}
    \label{fig:AWS_CB_money}
\end{figure}
\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{/Users/kenzie/Documents/HoGent/Bachelorproef/Images/AWS_CB_money2.png}
    \caption{Figuur van \href{}{AWS website}. Figuur toont berekening van prijzen per compileer minuut voor AWS.}
    \label{fig:AWS_CB_money2}
\end{figure}

Een klein detail dat maar zichtbaar was bij het bekijken van de prijzen stelsels. De gebruiker heeft de mogelijkheid om een besturingssysteem (OS) te kiezen bij het aanmaken van een AWS CodeBuild pijpleiding. Dit onderzoek heeft vastgesteld dat een Windows OS wel beschikbaar is maar niet in iedere datacenter locatie. Vaak is die optie ook duurder dan de Linux variant. Dit kan eventueel problemen veroorzaken met Windows specifieke voorbeelden. Ook is het moeilijk om informatie te vinden over hoe de gebruiker nu juist zelf een aangepaste compilatie motor definieert. 

AWS CodeDeploy is het CD gedeelte van de AWS CodePipeline. Het is volledige te beheren en aanpasbaar naar de noden van de gebruiker. Zo is het mogelijk om rechtstreeks vanuit de pijpleiding uit te rollen naar eender welke Amazon Cloud service of naar lokale omgevingen. Aangezien het mogelijk is om een zip met de software in te downloaden is het ook gemakkelijk te integreren met bestaande uitrol tools of werkwijzen. Deze feature is ook niet gratis. Volgende figuur~\ref{fig:AWS_CD_money} toont dit aan. Amazon rekent per update van een instantie een prijs aan. Daarbovenop moet er ook nog betaald worden voor de verbruikte opslag.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{/Users/kenzie/Documents/HoGent/Bachelorproef/Images/AWS_CD_money.png}
    \caption{Figuur van \href{}{AWS website}. Figuur toont prijs voor opslag op AWS.}
    \label{fig:AWS_CD_money}
\end{figure}

Naast een hele serie ontwikkeltools heeft Amazon ook tools toegevoegd om gedetailleerde rapporten en analyses te genereren van de uitgevoerde taken op AWS CodePipeline. Dit geeft juist zoals Google, de gebruiker goede inzichten in wat er juist allemaal gebeurt en verkeerd loopt. Ook kan de gebruiker op basis van foutmeldingen of status rapporten bepaalde acties instellen en laten uitvoeren.

Het zou mogelijk zijn om met AWS de gewilde functionaliteit de realiseren. Het zal wel zeer arbeid intensief zijn aangezien informatie over zelf een compilatie motor maken moeilijk te vinden is. Ook is het een stuk duurder. Dit onderzoek heeft ook vastgesteld dat Amazon een hele reeks van producten heeft waardoor het soms moeilijk is om door het bos de bomen te zien. Ook de prestatie van het platform blijft een vraagteken door de paper \autocite{Jackson2010}.

\subsection{IBM Cloud}
IBM Cloud is mogelijk een van de oudere Cloud platformen. Voor dat de term Cloud veel gebruikt was. IBM was al vroeg bezig met het idee om hardware open te stellen om dan meerdere machines of services op te laten draaien. In 1972 heeft IBM de eerste stappen gezet naar IaaS door voor hun mainframe een hypervisor te bouwen die toestond dat er meerdere instanties van een besturingssysteem op hetzelfde systeem draaide (VM’s). Dit is dan later geëvolueerd naar een meer typische Cloud infrastructuur. IBM heeft in de vroege jaren van hun Cloud systeem vooral hardware voorzien aan klanten. De zo genoemde privé Cloud. In 2007 werden dan de eerste stappen gezet naar de typisch Cloud infrastructuur door de verhuur van rekenkracht vanuit hun datacenters met hun hardware. 

Heden ten dage is IBM Cloud een stuk uitgebreider. Het valt onder te verdelen in 3 grote categorieën. SmartCloud Foundation, SmartCloud Services en SmartCloud Solutions. Volgens IBM is het hun bedoeling om de gaten in het aanbod van andere Cloud platform aanbieders op te vullen.

SmartCloud Foundation is een serie producten die privé Cloud en Hybride Cloud mogelijk moeten maken. Het biedt de infrastructuur, beheer, beveiliging, hardware en integratie aan. SmartCloud Services zijn dan de verschillende tools om dit te bereiken of te gebruiken. Dus Iaas of PaaS. SmartCloud Solutions is dan meer een pakket dat samenwerking, statistieken enz. moet mogelijk maken binnen de services en aanbiedingen van IBM.

Ook IBM Cloud heeft producten om een CI/CD pijpleiding te maken. Al is er toch een addertje onder het gras. IBM Cloud voorziet infrastructuur om vooral aan CD te kunnen voldoen. Dit met mogelijkheden om de infrastructuur te definiëren. Tools om de uitrol te beheren en te analyseren. Dit alles kan gecontroleerd worden, zoals alle andere Cloud platform aanbieders, door middel van een speciaal ontwikkelde command line interface (CLI) of door hun web portaal. Voor CI biedt IBM niks specifiek aan. Er bestaat wel de mogelijkheid om het Tekton framework te gebruiken op de Cloud infrastructuur van IBM maar dat kan bij iedere Cloud platform aanbieder. Dit valt ook buiten de scope van dit onderzoek.

Op basis van hun producten en services die ze aanbieden valt IBM Cloud uit de boot. Het zou zeer omslachtig zijn om IBM Cloud te gebruiken voor een Microsoft georiënteerde pijpleiding. Aangezien er geen specifieke compilatie technieken aanwezig zijn. Naast het Tekton framework. Ook is de prestatie van de IBM-datacenters niet slecht. Het zijn speciaal ontworpen centers met IBM eigen hardware en voorzieningen. Wat wel blijkt uit onderzoek van de ontwikkeltools van IBM Cloud, is dat IBM zich inzet om gemakkelijk te gebruiken tools te ontwikkelen die weinig moeite kosten om te implementeren en te configureren. Ook hebben ze als enige specifiek een Cloud aanbod voor Apple georiënteerde applicaties.

\subsection{Andere}
Naast de alom bekende giganten zoals Azure, Google Cloud, IBM Cloud en AWS zijn er nog een aantal andere Cloud platform aanbieders. Zo bestaat er nog Oracle Cloud en Digital Ocean. Er bestaan waarschijnlijk nog wel maar deze laat dit onderzoek buiten beschouwing.

Oracle Cloud zijn aanbod van producten en services liggen vooral in vier categorieën. IaaS, PaaS, Software as a Service (SaaS) en Data as a Service. Oracle Cloud hun aanbod is hoofdzakelijk hetzelfde als alle andere Cloud aanbieders. Juist zoals IBM Cloud heeft Oracle hun eigen hardware en eigen datacenters. Oracle Cloud biedt oplossingen en producten aan om DeVops te realiseren maar deze zijn vooral gefocust op het Java platform. Om deze reden valt ook Oracle Cloud uit de boot. Aangezien we in dit onderzoek trachten om een Microsoft georiënteerde pijpleiding willen realiseren. Het is wel mogelijk door gebruik te maken van het Tekton Framework. Maar dit laten we buiten beschouwing in dit onderzoek.

Digital Ocean is een Cloud platform speciaal gemaakt voor ontwikkelaars. Het Cloud platform is een van de jongere aanbieders. Digital Ocean is opgericht in 2011. Hun doel is om een omgeving aan te bieden aan ontwikkelaars waarin programmeurs gemakkelijk kunnen ontwikkelen en testen. Ook tracht Digital Ocean om deze omgeving open te stellen voor productie door het zeer gemakkelijk te maken om services en applicatie schaalbaar te maken op hun platform. Digital Ocean heeft jammer genoeg geen specifiek CI/CD aanbod. Het zou wel mogelijk zijn met het Tekton framework aangezien Digital Ocean Kubernetes ondersteund. Voor deze redenen valt Digital Ocean ook buiten de boot.

\subsection{Kandidaat}
Na al deze Cloud platform aanbieders hun aanbod naast elkaar te hebben gelegd, is er toch een platform dat er wat van tussen uitspringt. Dit is GCP. Daarom is deze Cloud aanbieder ook gekozen in dit onderzoek om een proof of concept op uit te werken. Google is niet alleen een stuk goedkoper, het gebruikt ook simpele en gemakkelijk te gebruiken containers. Ook is het een voordeel dat er gemakkelijk rechten kunnen aangemaakt worden op basis van de GitHub deelnemers. Google heeft ook de meest duidelijke informatiebronnen. Ook zijn het hypermoderne datacenters die over heel de wereld verspreid zijn. Dus prestatie zou geen probleem mogen zijn. Zie figuur~\ref{fig:GCP_NetwerkKaart}.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{/Users/kenzie/Documents/HoGent/Bachelorproef/Images/GCP_NetwerkKaart.png}
    \caption{Figuur van \href{}{Google Cloud website}. Figuur toont de connectiviteit van de verschillende datacenters verspreid over de wereld.}
    \label{fig:GCP_NetwerkKaart}
\end{figure}

\section{Kandidaat Selectie}
\label{sec:KandidaatSelectie}
Naast de kandidaat selectie op productaanbod en prijs, wil dit onderzoek ook de gebruiksvriendelijkheid in acht nemen. Hiervoor is er een simpele Java applicatie gebruikt. Alle Cloud platformen bieden starterhandleidingen aan voor het opzetten van een CI-pijpleiding voor Java op hun platform. Het doel van deze snelle test is om als eindresultaat een werkende Java JAR te hebben. Ook werd er bijgehouden hoelang het duurde om een pijpleiding te configureren om beter een idee te krijgen van hoe gebruiksvriendelijk het Cloud platform werkelijk is. 

De Java Applicatie bestaat uit een hoofdklasse en een testklasse. De hoofdklasse, ‘MessageUtil’ bevat een variabele voor een bericht te bewaren en vier methodes. De eerste methode is een constructor voor het aanmaken van een ‘MessageUtil’ object met een meegegeven bericht. De tweede methode print dit bericht. In de derde methode wordt er een toevoegsel aan dit bericht gevoegd. Ook wordt het geheel geprint. De laatste methode is een uitvoerbare methode die een ‘MessageUtil’ object maakt en de twee print methodes uitvoert. De code voor ‘MessageUtil.java’ wordt afgebeeld in \emph{figuur~\ref{code:messageutilj}}. 

De testklasse ‘TestMessageUtil’ bevat twee testen voor de print methodes. \emph{Figuur~\ref{code:messageutiltestj}}  toont de code voor dit Javabestand.

\lstset{
    language=java,
    breaklines=true,
    frame=single,
    commentstyle=\color{mygreen},
    keywordstyle=\color{blue},
    numberstyle=\tiny\color{mygray},
    stringstyle=\color{mymauve},
    captionpos=b,
    caption={Java bestand MessageUtil.java. Hoofd klasse van de applicatie \emph{MessageUtil}},
    label=code:messageutilj
}
\begin{lstlisting}
public class MessageUtil {
private String message;

    public MessageUtil(String message) {
        this.message = message;
    }

    public String printMessage() {
        System.out.println(message);
        return message;
    }

    public String salutationMessage() {
        message = "Hi!" + message;
        System.out.println(message);
        return message;
    }
    
    public static void main(String[] args) {
        MessageUtil mu = new MessageUtil("Idioten zijn er overal...");
        mu.printMessage();
        mu.salutationMessage();
    }
}
\end{lstlisting}

\lstset{
    language=java,
    caption={Java Test klasse MessageUtilTest.java, voor het testen van \emph{MessageUtil~\ref{code:messageutilj}}.},
    label=code:messageutiltestj
}
\begin{lstlisting}
import org.junit.Test;
import org.junit.Ignore;
import static org.junit.Assert.assertEquals;

public class TestMessageUtil {

    String message = "Robert";    
    MessageUtil messageUtil = new MessageUtil(message);

    @Test
    public void testPrintMessage() {      
        System.out.println("Inside testPrintMessage()");     
        assertEquals(message,messageUtil.printMessage());
    }

    @Test
    public void testSalutationMessage() {
        System.out.println("Inside testSalutationMessage()");
        message = "Hi!" + "Robert";
        assertEquals(message,messageUtil.salutationMessage());
    }
}
\end{lstlisting}

Deze Javabestanden worden op alle Cloud platformen gecompileerd aan de hand van de Maven compiler. Om de compiler te vertellen wat er moet gebeuren tijdens de compilatie van de Javabestanden, moet er een Xml-bestand aangemaakt worden waarin deze opties gedefinieerd staan. Deze ‘pom.xml’ wordt afgebeeld door \emph{figuur~\ref{code:pom}}. Hierin staat dat de meegeleverde Junit testen uitgevoerd moeten worden. Ook wordt er gedefinieerd dat de Java applicatie moet gecompileerd worden tot een JAR-bestand.

\lstset{
    language=XML,
    caption={XML-bestand voor de Maven compiler. Definieert stappen voor het compileren van een java applicatie.},
    label=code:pom
}
\begin{lstlisting}
<project xmlns="http://maven.apache.org/POM/4.0.0" 
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <groupId>org.example</groupId>
    <artifactId>messageUtil</artifactId>
    <version>1.0</version>
    <packaging>jar</packaging>
    <name>Message Utility Java Sample App</name>
    <dependencies>
        <dependency>
            <groupId>junit</groupId>
            <artifactId>junit</artifactId>
            <version>4.11</version>
            <scope>test</scope>
        </dependency>	
    </dependencies>
    <build>
            <plugins>
                <plugin>
                    <groupId>org.apache.maven.plugins</groupId>
                    <artifactId>maven-jar-plugin</artifactId>
                    <version>3.1.0</version>
                    <configuration>
                        <archive>
                            <manifest>
                                <addClasspath>true</addClasspath>
                                <classpathPrefix>lib/</classpathPrefix>
                                <mainClass>MessageUtil</mainClass>
                            </manifest>
                        </archive>
                    </configuration>
                </plugin>
            </plugins>
    </build>
</project>
\end{lstlisting}

Deze bestanden zijn toegevoegd aan een folder die de structuur hanteert uit \emph{figuur~\ref{code:treejava}}. Deze hoofdmap is dan geïnitialiseerd als een Git repositorie. Ook is er een gitignore aangemaakt. Deze Java applicatie is het startpunt voor alle testen voor gebruiksvriendelijkheid op de Cloud platformen. Op deze manier is er geprobeerd om op basis van eventuele verschillen een geschikte kandidaat te selecteren voor een Proof Of Concept. In de volgende secties~\ref{sec:JAA}, ~\ref{sec:JGCP} \& ~\ref{sec:JAD} wordt kort de werkwijze beschreven. Hier wordt de ‘hoe’ minder aangehaald omdat dit in de handleiding beschreven staat.

\lstset{
    language=bash,
    caption={Output van het tree commando in een java applicatie bestanden structuur.},
    label=code:treejava
}
\begin{lstlisting}
Demo_java_aws/
`--- .gitignore
`--- pom.xml
`--- src
    `--- main
        `--- java
           `--- MessageUtil.java
    `--- test
        `--- java
           `--- TestMessageUtil.java
\end{lstlisting}

\subsection{Java Amazon AWS}
\label{sec:JAA}


\subsection{Java Google Cloud Platform}
\label{sec:JGCP}

\subsection{Java Azure DeVops}
\label{sec:JAD}

\section{Proof Of Concept}
\label{sec:POC}
Omdat Aucxis met een Microsoft georiënteerde werkwijze zit, moet er worden aangetoond dat het mogelijk is om dit te realiseren op GCP. Voor deze Proof Of Concept (POC) wordt er een CI/CD pijpleiding geconfigureerd. Hierin wordt er een simpele .NET Core applicatie gecompileerd. Ook de meegeleverde testen worden uitgevoerd tijdens de compilatie. Hierna wordt de applicatie en de bijbehorende componenten gecomprimeerd en naar een lokale fileserver geüpload. De gecompileerde applicatie kan dan uitgebreid getest worden in een lokale test omgeving. Ook is er een stap voorzien in de pijpleiding om de gecompileerde applicatie tijdelijk op het Cloud platform te bewaren. Dit voor het geval er iets verkeerd loopt tijdens het testen of tijdens het uploaden.

De .Net applicatie is een simpele .Net core console applicatie. Het bestaat uit een klasse, \emph{MessageUtil~\ref{code:messageutil}}. Deze klasse bevat een variabele, twee constructors, een methode om de variabele op te vragen, een methode om de variabele te tonen met een toevoegsel en een hoofdmethode die uitvoerbaar is.

\lstset{
     language=C,
     breaklines=true,
     frame=single,
     commentstyle=\color{mygreen},
     keywordstyle=\color{blue},
     numberstyle=\tiny\color{mygray},
     stringstyle=\color{mymauve},
     captionpos=b,
     caption={C\# bestand MessageUtil.cs. Hoofd klasse van de applicatie \emph{MessageUtil}},
     label=code:messageutil
}
\begin{lstlisting}
using System;
using System.Threading;

namespace MessageUtil {
    public class MessageUtilProgram {
    
        private String p_message;
        
        private MessageUtilProgram() { }
        public MessageUtilProgram(String message) {
            p_message = message;
        }
        
        public String Message {
            get { return p_message; }
        }
        public String SaluteMessage(String m) {
            Console.WriteLine("Hello\n{0}", m);
            return "hello" + m;
        }
        
        static void Main(string[] args) {
            MessageUtilProgram mup = new MessageUtilProgram("Aucxis");
            Console.WriteLine("{0}", mup.Message);
            //mup.SaluteMessage(mup.Message);
            Thread.Sleep(60000);
        }
    }
}
\end{lstlisting}

Daarnaast is er ook een testklasse voorzien, \emph{MessageUtilTest~\ref{code:messageutiltest}}. Hierin staan er twee methodes. De eerste methode test de constructor die de variabele moet instellen. De tweede methode test een van de print methodes.

\lstset{
    language=C,
    caption={C\# Test klasse MessageUtilTest.cs, voor het testen van MessageUtil~\ref{code:messageutil}.},
    label=code:messageutiltest
}
\begin{lstlisting}
using Microsoft.VisualStudio.TestTools.UnitTesting;
using MessageUtil;
    
namespace MessageUtilTest {

    [TestClass]
    public class MessageUtilTests {
    
        [TestMethod]
        public void ConstructWorks() {
            string testmessage = "Test";
            MessageUtilProgram mup = new MessageUtilProgram(testmessage);

            string value = mup.Message;
            Assert.AreEqual(testmessage, value,"Message didn't set correctly");
        }
        
        [TestMethod]
        public void SaluteWorks() {
            string testmessage = "Test";
            string expected = "helloTest";
            MessageUtilProgram mup2 = new MessageUtilProgram(testmessage);

            string value = mup2.SaluteMessage(mup2.Message);
            Assert.AreEqual(expected, value, "Message didn't salute correctly");
        }
    }
}
    
\end{lstlisting}

De applicatie wordt in beide gevallen onveranderd gebruikt zodanig dat een potentieel verschil zichtbaar wordt. Dit is de basis waaruit vertrokken is voor de vergelijkende POC. Om de prijs en het aantal benodigde producten zo laag mogelijk te houden, is er in dit onderzoek gekozen om Git en GitHub te gebruiken als versiebeheersysteem. GitHub is volledig ondersteund door beide platformen. Ook voorzien beide Cloud platformen applicaties op GitHub om automatisch de gewenste repositories te verbinden aan de CI/CD pijpleidingen.

Het uploaden van de gecomprimeerde applicatie wordt gedaan door middel van Secure File Transfer Protocol (SFTP) op een Linux Ubuntu machine. Deze maakt verbinding met een Docker container die lokaal op een Windows Server 2019 draait. Deze\emph{~\href{https://hub.docker.com/r/atmoz/sftp/}{Docker container}} deelt een directory met Windows zodanig dat dit volledig modulair is met andere besturingssystemen of situaties. SFTP werkt onderliggend op basis van Secure Shell (SSH). Om verbinding te maken is dus een wachtwoord nodig. Dit is een probleem aangezien de virtuele systemen in de Cloud niet interactief zijn. Dit is opgelost door het gebruik van\emph{~\href{https://linux.die.net/man/1/sshpass}{SSHPASS}}. Dit Linux pakket heeft de mogelijkheid om aan SSH-toepassingen het wachtwoord mede te geven. Weliswaar zonder encryptie van het wachtwoord. Hierdoor is het wachtwoord leesbaar. Er wordt enkel op deze wijze gewerkt om het geheel relatief simpel te houden. Voor productie omgevingen zou er met SSH-sleutels gewerkt moeten worden. De SFTP operatie op de Linux Ubuntu in de Cloud, wordt uitgevoerd door middel van het \emph{script~\ref{code:filetrans}}. Dit Bash script zorgt ervoor dat het SSHPASS pakket beschikbaar is en voert de SFTP transactie uit.

\lstset{
    language=bash,
    caption={Bash script filetrans.sh. Script installeert de juiste Linux packages en kopieert de bestanden met SFTP.},
    label=code:filetrans
}
\begin{lstlisting}
#! /bin/bash
apt-get update
apt-get -y upgrade
apt-get -y install sshpass
sshpass -p 'pwd' sftp -o StrictHostKeyChecking=accept-new -P 5151 -oBatchMode=no -b - TestU@server << !
cd documents
put /workspace/MessageUtil/bin/Release/netcoreapp3.1/win10-x64/messageutil-win10-x64.tar.gz
bye
!
\end{lstlisting}

De Cloud specifieke configuratie bestanden worden in de volgende secties verder verduidelijkt. Voor GCP in \emph{sectie~\ref{sec:VergelijkingGCP}} en voor het Azure DeVops platform \emph{sectie~\ref{sec:VergelijkingADV}}.

\subsection{Google Cloud Platform}
\label{sec:VergelijkingGCP}
Voor deze POC is er een nieuw project aangemaakt op Google Cloud. Als op Google Cloud een project verwijderd wordt, worden ook alle resources en aanrekeningen stopgezet. Ook omdat er dan per project producten en services toegewezen kunnen worden. Zo kan er optimaal voldaan worden aan de gebruiker zijn noden. Het nieuw gecreëerde project, heeft de naam ‘net-demo-project’ gekregen zoals in \emph{figuur~\ref{fig:GCP_POC_projn}}.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{/Users/kenzie/Documents/HoGent/Bachelorproef/Images/gcp_net_demo_projn.png}
    \caption{Figuur toont het scherm om een nieuw project te creëren op Google Cloud.}
    \label{fig:GCP_POC_projn}
\end{figure}

Om Code Build op Google Cloud te gebruiken moest eerst de API via de online console geactiveerd worden. Ook moest er nog een Storage Bucket aangemaakt worden voor het opslaan van de gecompileerde applicatie. De Storage service is standaard geactiveerd en hoefde dus niet aangezet te worden. Deze Storage Bucket heeft de naam ‘net-demo-output-bucket’ gekregen. Ook belangrijk was de selectie voor de locatie van deze Storage Bucket. Hier is er gekozen voor een geografisch zo dicht mogelijke locatie. Dit om de overdracht tijden van bestanden zo minimaal mogelijk te houden. Alle andere opties zijn onveranderd gebleven. Ook is er de mogelijkheid om toegangsrechten toe te kennen. Dit kan interessant zijn voor een productie omgeving. \emph{Figuur~\ref{fig:GCP_POC_sb}}toont de gecreëerde Storage Bucket en de geselecteerde opties.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{/Users/kenzie/Documents/HoGent/Bachelorproef/Images/gcp_net_demo_sb.png}
    \caption{Figuur toont het scherm met een gecreëerde Storage Bucket en de geconfigureerde opties op Google Cloud.}
    \label{fig:GCP_POC_sb}
\end{figure}

Hierna is er een nieuwe map aangemaakt op de gebruiker zijn computer voor de applicatie. Deze is geïnitialiseerd als een Git repositorie. Hierin zijn dan de bestanden, \emph{MessageUtil~\ref{code:messageutil}} \& \emph{MessageUtilTest~\ref{code:messageutiltest}} voor de .Net applicatie in geplaatst. Ook het \emph{script~\ref{code:filetrans}} voor de bestanden overdracht met SFTP is hierbij toegevoegd. Hiernaast is er ook een gitignore aangemaakt. \emph{Figuur~\ref{code:gcpgittree}} toont een tree van de bestanden en mappen structuur.

\lstset{
    language=bash,
    caption={Tree van de bestanden structuur voor de Proof Of Concept op Google Cloud.},
    label=code:gcpgittree
}
\begin{lstlisting}
poc_gcp_dotnet/
`--- .git
`--- .gitignore
`--- MessageUtil
      `--- MessageUtil.csproj
      `--- MessageUtilProgram.cs
`--- MessageUtil.sln
`--- MessageUtilTest
      `--- MessageUtilTest.csproj
      `--- MessageUtilTests.cs
`--- filetrans.sh
\end{lstlisting}

Vervolgens moest er connectie gemaakt worden met het gecreëerde project op Google Cloud met Google Cloud CLI. Hiervoor is op de CLI van de gebruiker zijn computer \emph{gcloud init -console only} uitgevoerd. Vervolgens is de wizard gevolgd en is het correcte project geselecteerd. Als volgende moest de configuratie van de CI/CD pijpleiding gemaakt worden. Zoals voorheen aangehaald werkt Google Cloud Code Build met Docker containers om al de gewenste taken uit te voeren. Voor deze POC is er gekozen om een Docker container van Microsoft zelf te gebruiken. Er is gekozen voor een .Net Core SDK container op \emph{\href{https://hub.docker.com/_/microsoft-dotnet-core-sdk}{DockerHub}}. Deze container wordt onderhouden door Microsoft zelf en heeft daarnaast ook uitgebreide documentatie ter beschikking op \emph{\href{https://github.com/dotnet/dotnet-docker/blob/master/samples/README.md}{GitHub}}. Zo moest er geen aangepaste container gemaakt worden die in de toekomst dan problemen zou kunnen krijgen naarmate de software update. Deze container is gebaseerd op een licht gewicht Linux machine. Hierop staat dan de SDK van Microsoft om .Net applicaties te testen, compileren, publiceren, enz.

Pijpleidingen voor CI op Google Cloud Code Build worden geconfigureerd met behulp van een YAML-bestand. Voor deze POC zijn er vier verschillende stappen gedefinieerd met elk hun eigen doel. De eerste drie stappen maken allemaal gebruik van de door Microsoft gemaakte Docker container, ‘mcr.microsoft.com/dotnet/ore/sdk:3.1’. De laatste Docker container is een Ubuntu container. In de eerste stap worden de testen in \emph{MessageUtilTest~\ref{code:messageutiltest}} uitgevoerd. De tweede stap compileert de code van de applicatie specifiek voor een 64 Bit Windows 10 platform en maakt een folder publish aan. In een derde stap wordt het Bash script ‘tarring.sh’ uitgevoerd dat deze publish map comprimeert. \emph{Figuur~\ref{code:tarring}} toont dit Bash script. In een laatste stap wordt het 'filetrans' \emph{script~\ref{code:filetrans}} uitgevoerd. Ook is er een stukje code voorzien dat het gemaakte ‘artifact’ (de gecomprimeerde map) gaat uploaden naar een Storage Bucket op Google Cloud. \emph{Figuur~\ref{code:cloudbuildnet}} toont deze cloubuild.yaml. Google Cloud Code Build gaat automatisch bij de overgang van iedere stap naar een andere virtuele machine, het volume waarin gewerkt wordt monteren. Hierdoor zijn er geen speciale stappen of acties nodig om bestanden tussen de verschillende machines uit te wisselen.

\lstset{
    language=bash,
    caption={Bash script om een bepaalde folder te comprimeren tot een .tar.gz.},
    label=code:tarring
}
\begin{lstlisting}
#! /bin/bash
cd /workspace/MessageUtil/bin/Release/netcoreapp3.1/win10-x64/ && tar -zcvf messageutil-win10-x64.tar.gz ./publish/
\end{lstlisting}

\lstset{
    language=bash,
    caption={YAML-bestand voor de configuratie van de .Net pijpleiding op Google CLoud.},
    label=code:cloudbuilnet
}
\begin{lstlisting}
steps:
 - name: 'mcr.microsoft.com/dotnet/core/sdk:3.1'
    entrypoint: 'dotnet'
    args: [ 'test' ]
 - name: 'mcr.microsoft.com/dotnet/core/sdk:3.1'
    entrypoint: 'dotnet'
    args: [ 'publish', '-c', 'Release', '-r', 'win10-x64' ]
 - name: 'mcr.microsoft.com/dotnet/core/sdk:3.1'
    entrypoint: 'bash'
    args: [ './tarring.sh' ]
 - name: 'ubuntu'
    entrypoint: 'bash'
    args: [ './filetrans.sh']
artifacts:
 objects:
    location: 'gs://net-demo-output-bucket/'
    paths: ['/workspace/MessageUtil/bin/Release/netcoreapp3.1/win10-x64/messageutil-win10-x64.tar.gz']
\end{lstlisting}

Nadat al deze bestanden aangemaakt zijn, is deze pijpleiding voor het eerst uitgevoerd. Hiervoor is de Google Cloud CLI gebruikt op de gebruiker zijn computer. Het commando\emph{gcloud builds submit} gaat de volledige Git repositorie kopiëren naar een tijdelijke Storage Bucket en start vervolgens de pijpleiding op volgens de configuratie vanuit 'cloudbuild.yaml'. Eenmaal dat deze pijpleiding volledig zonder fouten werkte, is de Git repositorie op GitHib geplaatst. Vervolgens is er via de online console op Google Cloud een Trigger aangemaakt om deze pijpleiding automatisch te laten uitvoeren bij het updaten van een bepaalde tak op GitHub. Hiervoor is GitHub gelinkt aan Google Cloud. \emph{Figuur~\ref{fig:GCP_POC_trigger}} toont de gemaakte Trigger en ook de specifieke tag die gebruikt is voor de tak op GitHub. Er is gekozen om deze Trigger op een specifieke tak van de GitHub repositorie te configureren om het aantal keren dat deze pijpleiding uitgevoerd wordt te kunnen verminderen. Zo kunnen de ontwikkelaars zelf kiezen wanneer ze de code willen compileren, door naar deze specifieke tak te uploaden. Dit vermijdt ook dat er in het wilde weg compilatie commando’s worden uitgevoerd door de ontwikkelaars zelf.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{/Users/kenzie/Documents/HoGent/Bachelorproef/Images/gcp_net_demo_trigger.png}
    \caption{Figuur toont het scherm  van Google Cloud met een gecreëerde Trigger op de tak 'Build' op GitHub.}
    \label{fig:GCP_POC_trigger}
\end{figure}

Eenmaal dit gebeurd is kon de trigger getest worden door een commit uit te voeren op GitHub. Vervolgens was het resultaat te testen op de lokale Windows Server 2019. Ook was er een gedetailleerd rapport te zien op de console van Google Cloud zelf. Om de applicatie uit te voeren moest simpel weg het gecomprimeerde bestand uitgepakt worden en uitgevoerd worden. \emph{Figuur~\ref{fig:GCP_POC_result}} toont het resultaat van de uitgevoerde applicatie op de lokale machine. \emph{Figuur~\ref{fig:GCP_POC_run}} toont de uitgevoerde compilatie op Google Cloud.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{/Users/kenzie/Documents/HoGent/Bachelorproef/Images/gcp_net_demo_result.png}
    \caption{Figuur toont de uitvoer van de gecompileerde applicatie op een lokale Windows Server 2019. Applicatie is gekopieerd door middel van \emph{script~\ref{code:filetrans}}.}
    \label{fig:GCP_POC_result}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{/Users/kenzie/Documents/HoGent/Bachelorproef/Images/gcp_net_demo_run.png}
    \caption{Figuur toont het resultaat van de compilatie stappen op Google Cloud. Ook zijn er een aantal andere logs te bekijken op dit scherm.}
    \label{fig:GCP_POC_run}
\end{figure}

Tot slot is er op de online console van Google Cloud een simpel dashboard te zien. Dit dashboard toont de laatst uitgevoerde compilatie trigger van het project. Ook toont het eventuele fouten, gemiddelde tijden, wat de compilatie heeft doen uitvoeren, commit ID van GitHub, enz. \emph{Figuur~\ref{fig:GCP_POC_dashboard}} toont een voorbeeld van zo een dashboard.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{/Users/kenzie/Documents/HoGent/Bachelorproef/Images/gcp_net_demo_dashboard.png}
    \caption{Figuur toont een simpel dashboard met gegevens over de compilatie pijpleiding.}
    \label{fig:GCP_POC_dashboard}
\end{figure}

Door deze POC op te stellen is er gebleken dat Google Cloud Build Code gemakkelijk te gebruiken is. Dat is, eenmaal de gebruiker er thuis in is. Er bestaat redelijk wat documentatie over wat allemaal mogelijk is in een ‘cloudbuild.yaml’. Helaas is voor een beginner het niet gemakkelijk om te verstaan hoe de verschillende containers met elkaar samenwerken en waar nu alle bestanden staan. Ook is een goede kennis van de containers nodig om te kunnen verstaan wat er allemaal mogelijk is. Dit zorgt ervoor dat het lang kan duren vooraleer er een pijpleiding operationeel is. Ook is het spijtig dat er niet meer analytics te verkrijgen zijn op Google Cloud Code Build. De gebruiker heeft enkel de analytics van wat er door Google zelf wordt aangeboden. Na het opstellen van deze POC is er ook gebleken dat Google Cloud niet zo duur is. Al het testen en uitproberen heeft slechts 0.40 euro gekost. Het kan interessant zijn om in een later onderzoek te kijken of het niet mogelijk is om de gegenereerde log bestanden van Google Cloud te downloaden en te gebruiken voor eigen visualisatie systemen zoals: Grafana. 

\subsection{Azure DeVops}
\label{sec:VergelijkingADV}
Naast de POC op Google Cloud is het ook nog interessant om dezelfde opstelling eens te maken in Azure DeVops. Dit om de ervaring en de functionaliteit naast elkaar te kunnen leggen. Voor de POC op Azure DeVops is er een nieuw DeVops project aangemaakt. Dit project heeft de naam ‘poc\_azure\_dotnet’ gekregen. \emph{Figuur~\ref{fig:Azure_POC_proj}} toont het aangemaakte project. Net zoals GCP bevatten projecten alle toegewezen producten en services die geconfigureerd geweest zijn. Ook is het gemakkelijk opnieuw te verwijderen en stopt dan ook de aanrekening.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{/Users/kenzie/Documents/HoGent/Bachelorproef/Images/azure_net_demo_proj.png}
    \caption{Figuur toont een nieuw aangemaakt project op Azure DeVops.}
    \label{fig:Azure_POC_proj}
\end{figure}

Deze POC vertrekt vanuit dezelfde applicatie als bij GCP. Hiervoor is er een nieuwe map aangemaakt op de gebruiker zijn computer voor de applicatie. Deze is geïnitialiseerd als een Git repositorie. Hierin zijn dan de bestanden \emph{MessageUtil~\ref{code:messageutil}} \& \emph{MessageUtilTest~\ref{code:messageutiltest}} voor de .Net applicatie in geplaatst. Ook is er een gitignore aangemaakt. \emph{Figuur~\ref{code:azuregittree}} toont een tree van de bestanden en mappen structuur. Deze repositorie is dan geüpload naar GitHub.

\lstset{
    language=bash,
    caption={Tree van de bestanden structuur voor de Proof Of Concept op Azure DeVops.},
    label=code:azuregittree
}
\begin{lstlisting}
poc_azure_dotnet/
`--- .gitignore
`--- MessageUtil
    `--- MessageUtil.csproj
    `--- MessageUtilProgram.cs
`--- MessageUtil.sln
`--- MessageUtilTest
    `--- MessageUtilTest.csproj
    `--- MessageUtilTests.cs
\end{lstlisting}

Hierna is er op Azure DeVops een nieuwe pijpleiding aangemaakt. Dit was zeer gemakkelijk te volgen door middel van de online wizard. Eerst moest er gekozen worden wat versiebeheersysteem de gebruiker gebruikt. Hier is er gekozen voor GitHub. Vervolgens vraagt Azure DeVops de gebruiker toestemming voor het uitlezen van de repositories. Tegelijk wordt ook de Azure DeVops pijpleiding applicatie toegevoegd aan de gebruiker zijn GitHub. Na de initialisatie van de Azure DeVops applicatie voor GitHub moest er een reposirotrie geselecteerd worden. Hier is er gekozen voor de zojuist gemaakte GitHub repositorie. Azure DeVops leest deze repositorie uit en stelt dan op basis van de bestanden de juiste compilatie oplossing voor. Voor deze POC stelde Azure DeVops .Net Core voor als compilatie programma. Er is voor dezen oplossing gekozen. Azure DeVops toont hierna een Yaml-bestand, ‘azure-pipelines.yml’, met voor gemaakte stappen. Dit YAML-bestand bevat drie stappen. Een eerste stap die de juiste pakketten installeert op de virtuele machine. In een tweede stap wordt de applicatie gecompileerd. In de derde stap worden de meegeleverde testen uit \emph{MessagUtilTest~\ref{code:messageutiltest}} uitgevoerd. \emph{Figuur~\ref{code:azure-pipelines-poc}} toont dit YAML-bestand.

\lstset{
    language=bash,
    caption={YAML-bestand voor de configuratie van de .Net pijpleiding op Azure DeVops.},
    label=code:azure-pipelines-poc
}
\begin{lstlisting}
# .NET Desktop
# Build and run tests for .NET Desktop or Windows classic desktop solutions.
# Add steps that publish symbols, save build artifacts, and more:
# https://docs.microsoft.com/azure/devops/pipelines/apps/windows/dot-net

trigger:
    - master

pool:
    vmImage: 'windows-latest'

variables:
    solution: '**/*.sln'
    buildPlatform: 'Any CPU'
    buildConfiguration: 'Release'

steps:
- task: NuGetToolInstaller@1

- task: NuGetCommand@2
    inputs:
    restoreSolution: '$(solution)'

- task: VSBuild@1
    inputs:
    solution: '$(solution)'
    platform: '$(buildPlatform)'
    configuration: '$(buildConfiguration)'

- task: VSTest@2
    inputs:
    platform: '$(buildPlatform)'
    configuration: '$(buildConfiguration)'
\end{lstlisting}

Verwacht was dat dit een werkend vertrekpunt is voor de pijpleiding. Zeker omdat deze applicatie met een Microsoft specifieke taal gemaakt is, met behulp van het .Net framework dat ook Microsoft specifiek is. In eerste instantie leek deze pijpleiding te werken. Maar na het bekijken van de logbestanden is er vastgesteld dat de testen niet werden uitgevoerd. Er is gezocht naar een oplossing voor dit probleem. Er is geen duidelijke oplossing gevonden voor de huidige configuratie. De documentatie over deze modules was zeer onduidelijk en moeilijk te begrijpen. Zeker vanuit het standpunt van een beginner. In dit opzicht is er gekozen om opnieuw te beginnen aan de hand van een andere \emph{\href{https://docs.microsoft.com/en-us/azure/devops/pipelines/ecosystems/dotnet-core?view=azure-devops}{handleiding}} op Azure. Deze gebruikt een voor gemaakte Windows virtuele machine met .Net core voor geïnstalleerd. Over deze module is uitgebreide documentatie te vinden. Daarnaast zijn er door Microsoft ook voorbeelden ter beschikking. Dit was dan ook het perfecte vertrekpunt.

Dit nieuw YAML-bestand bestaat uit zes stappen. In een eerste stap wordt de ‘MessageUtil’ applicatie volledige herbouwt. Deze staat dan klaar voor verdere stappen. In de tweede stap wordt de applicatie gecompileerd. De derde stap voert de meegeleverde testen uit. Ook publiceert het de resultaten op Azure DeVops. \emph{Figuur~\ref{fig:Azure_POC_testr}} toont een voorbeeld van uitgevoerde testen. De vierde stap compileert een uitrol versie voor het 64 bit Windows 10 platform in een map, publish. In de vijfde stap wordt er een PowerShell script uitgevoerd. Dit Script comprimeert de map publish. \emph{Figuur~\ref{code:zipping}} toont het ‘zipping.ps1’ script. In een laatste stap wordt deze gecomprimeerde map gepubliceerd als een artifact zodanig dat de applicatie klaarstaat om in een latere stap te worden uitgerold. \emph{Figuur~\ref{code:azure-pipelines-poc-n}} toont het verbeterde ‘azure-pipelines.yml’. Vervolgens is deze code toegevoegd op GitHub.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{/Users/kenzie/Documents/HoGent/Bachelorproef/Images/azure_net_demo_testr.png}
    \caption{Figuur toont een simpel dashboard met gegevens over de uitgevoerde testen.}
    \label{fig:Azure_POC_testr}
\end{figure}

\lstset{
    language=C,
    caption={PowerShell script dat een map compresseert. Wordt gebruikt om alle .Net Framework afhankelijkheden mee te verpakken.},
    label=code:zipping
}
\begin{lstlisting}
$compress = @{
Path= "d:\a\1\s\MessageUtil\bin\Release\netcoreapp3.1\win10-x64\publish\*"
CompressionLevel = "Fastest"
DestinationPath = "d:\a\1\s\MessageUtil.zip"
}
Compress-Archive @compress
\end{lstlisting}

\lstset{
    language=bash,
    caption={Verbeterd YAML-bestand voor de configuratie van de .Net pijpleiding op Azure DeVops.},
    label=code:azure-pipelines-poc-n
}
\begin{lstlisting}
trigger:
    - master

pool:
    vmImage: 'windows-latest'

variables:
    buildConfiguration: 'Release'
    runtimeIdentifier: 'win10-x64'

steps:
- task: DotNetCoreCLI@2
    inputs:
        command: 'restore'
        restoreDirectory: '$(System.DefaultWorkingDirectory)'
        #packDirectory: '$(System.DefaultWorkingDirectory)'
        displayName: 'DotNet Restore Project'

- task: DotNetCoreCLI@2
    inputs:
        command: 'build'
        arguments: '--configuration $(buildConfiguration)'
        displayName: 'DotNet Build $(buildConfiguration)'

- task: DotNetCoreCLI@2
    inputs:
        command: 'test'
        projects: '**/*Test/*.csproj'
        arguments: '--configuration $(buildConfiguration) --collect "Code coverage"'
        displayName: 'DotNet Test Build'
    
- task: DotNetCoreCLI@2
    inputs:
        command: 'publish'
        publishWebProjects: false
        arguments: '--configuration $(buildConfiguration) -r $(runtimeIdentifier)'
        zipAfterPublish: false
        displayName: 'DotNet Publish Build'

- task: PowerShell@2
    inputs:
        targetType: 'filePath'
        filePath: $(System.DefaultWorkingDirectory)\ziping.ps1
        errorActionPreference: 'stop'
        displayName: 'DotNet Zip Publish'

- task: PublishPipelineArtifact@1
    inputs:
        targetPath: $(System.DefaultWorkingDirectory)\MessageUtil.zip
        artifactName: MessageUtil
        displayName: 'Upload Zip'
\end{lstlisting}

Het CI-gedeelte van de pijpleiding werkt met deze code. Voor het CD-gedeelte moest er een nieuwe uitrol pijpleiding gemaakt worden. Op Azure DeVops is er een nieuwe release gemaakt bestaande uit een Linux Ubuntu machine. Deze virtuele machine download het gemaakte artifact en verzend dit bestand naar de lokale Windows Server. Deze virtuele machine voert het script uit \emph{figuur~\ref{code:filetrans}} uit. Het instellen van deze uitrol pijpleiding is zeer gemakkelijk door de online wizard. \emph{Figuur~\ref{fig:Azure_POC_release}} toont het instellen van de virtuele machine. Ook zijn er talloze opties voor het instellen van toestemmingen, rechten, controles, enz. Dit kan interessant zijn in een productie omgeving. Deze POC laat dit buiten beschouwing. \emph{Figuur~\ref{fig:Azure_POC_pijp}} toont de volledige pijpleiding.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{/Users/kenzie/Documents/HoGent/Bachelorproef/Images/azure_net_demo_release.png}
    \caption{Figuur toont hoe een release pijpleiding op Azure DeVops geconfigureerd wordt. In dit geval wordt er een Ubuntu machine geconfigureerd met een script.}
    \label{fig:Azure_POC_release}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{/Users/kenzie/Documents/HoGent/Bachelorproef/Images/azure_net_demo_pijp.png}
    \caption{De figuur toont een kort overzicht van de totaal gemaakte pijpleiding op Azure DeVops.}
    \label{fig:Azure_POC_pijp}
\end{figure}

Azure DeVops heeft ook zeer goede analytics. Voor deze POC zijn er een aantal voorbeelden gemaakt. Net zoal Google Cloud heeft Azure ook Dashboards. \emph{Figuur~\ref{fig:Azure_POC_dashboard}} toont een overzicht van het project.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{/Users/kenzie/Documents/HoGent/Bachelorproef/Images/azure_net_demo_dashboard.png}
    \caption{Figuur toont een simpel dashboard met gegevens over de compilatie pijpleiding.}
    \label{fig:Azure_POC_dashboard}
\end{figure}

Uit deze POC is gebleken dat Azure DeVops veel minder complex is om te configureren dan Google Cloud Code Build. Dit komt door de gemakkelijk te gebruiken wizards die de gebruiker door de configuratie heen gidsen. Zo voelt de complexiteit van het configureren van een pijpleiding minder zwaar aan. Uit deze POC is gebleken dat de standaardoplossing die Azure DeVops voorstelt niet altijd even gemakkelijk is om aan te passen naar de gebruiker zijn noden. Deze POC heeft ook aangetoond dat de documentatie van Azure DeVops redelijk complex kan zijn. Zelfs na meerdere projecten te hebben getest, zijn sommige zaken nog niet helemaal duidelijk. Azure DeVops biedt zeer uitgebreide hulpmiddelen aan om allerlei data te visualiseren. Deze dashboards zijn gemakkelijk te creëren. Ook zijn deze zeer duidelijk en overzichtelijk. Dit in tegenstelling tot Google Cloud. In vergelijking met Azure DeVops is Google Cloud gemakkelijker om aangepaste pijpleidingen te maken. Dit omdat het intuïtiever is om de configuratie YAML-bestanden te maken. Ook omdat Google Cloud Code Build met Docker containers werkt. Dit zorgt ervoor dat compileer machines veel uitgebreider kunnen aangepast worden naar de noden van de gebruiker.

Benaderd vanuit het Microsoft ecosysteem is Azure DeVops een zeer goede en logische keuze. Zeker omdat een hele hoop producten en services, die anders aanvullende kosten hebben, vrij te gebruiken zijn. Ook zijn alle hulpmiddelen om software te ontwikkelen volledig geïntegreerd in het platform. Gebruikers die buiten dit ecosysteem werken kijken beter naar Google Cloud in samenwerking met andere tools en oplossingen.


%Aantal woorden: 3933%